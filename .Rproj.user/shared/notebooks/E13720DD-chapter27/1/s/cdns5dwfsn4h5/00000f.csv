"0","# 文字列の操作を行うためのライブラリ"
"0","pacman::p_load(tm, SnowballC)"
"0",""
"0","# SMS Spam Collection Datasetをロード（kaggleから拾ってくる）"
"0","sns <- read.csv(""./data/spam.csv"", stringsAsFactors = F, encoding = 'UTF-8')"
"0","sns <- sns[,1:2]"
"0","colnames(sns) <- c(""type"", ""text"")"
"0",""
"0","# 文字列をコーパスに変換"
"0","data_corpus <- VCorpus(VectorSource(sns$text))"
"0",""
"0","# データのクリーニング"
"0","clean_corpus <- tm_map(data_corpus,removeWords,stopwords(kind = ""english"")) # 英語以外の文字を取り除く"
"0","clean_corpus <- tm_map(clean_corpus,stripWhitespace) # 複数のスペースを1つに変換"
"0","clean_corpus <- tm_map(clean_corpus, content_transformer(tolower)) # 大文字を小文字に変換"
"0","clean_corpus <- tm_map(clean_corpus,removePunctuation) # 句読点を取り除く"
"0","clean_corpus <- tm_map(clean_corpus,removeNumbers) # 数字を取り除く"
"0","clean_corpus <- tm_map(clean_corpus,stemDocument) # stem化をする（pay, paid, payingなどをpayに統一）"
"0",""
"0","dados_dtm <- DocumentTermMatrix(clean_corpus) # termと文章を行列にする"
"0","# dados_dtmの中身，行はsnsのテキスト，列は単語，数字が入っていると単語が含まれる"
"0","inspect(dados_dtm[1:5, 1:8]) "
"1","<<DocumentTermMatrix (documents: 5, terms: 8)>>
"
"1","Non-/sparse entries: 0/40
"
"1","Sparsity           : 100%
"
"1","Maximal term length: 11
"
"1","Weighting          : term frequency (tf)
"
"1","Sample             :
"
"1","    Terms
"
"1","Docs"
"1"," ���"
"1"," aah"
"1"," aaniy"
"1"," aaooooright"
"1"," aathi"
"1"," aathilov"
"1"," abbey"
"1"," abdomen"
"1","
   1"
"1","   0"
"1","   0"
"1","     0"
"1","           0"
"1","     0"
"1","        0"
"1","     0"
"1","       0"
"1","
   2"
"1","   0"
"1","   0"
"1","     0"
"1","           0"
"1","     0"
"1","        0"
"1","     0"
"1","       0"
"1","
   3"
"1","   0"
"1","   0"
"1","     0"
"1","           0"
"1","     0"
"1","        0"
"1","     0"
"1","       0"
"1","
   4"
"1","   0"
"1","   0"
"1","     0"
"1","           0"
"1","     0"
"1","        0"
"1","     0"
"1","       0"
"1","
   5"
"1","   0"
"1","   0"
"1","     0"
"1","           0"
"1","     0"
"1","        0"
"1","     0"
"1","       0"
"1","
"
"0","# 訓練データとテストデータに分ける"
"0","data_dtm_train <- dados_dtm[1:4169, ]"
"0","data_dtm_test <- dados_dtm[4170:5559, ]"
"0",""
"0","# ラベルは別途分ける"
"0","data_train_labels <- sns[1:4169, ]$type"
"0","data_test_labels <- sns[4170:5559, ]$type"
"0",""
"0","# スパム/ハムの割合を表示（大体87%ハムで同じ）"
"0","prop.table(table(data_train_labels))"
"1","data_train_labels
"
"1","      ham "
"1","     spam "
"1","
"
"1","0.8644759 "
"1","0.1355241 "
"1","
"
"0","prop.table(table(data_test_labels))"
"1","data_test_labels
"
"1","      ham "
"1","     spam "
"1","
"
"1","0.8705036 "
"1","0.1294964 "
"1","
"
"0","# 5回以上見つかったWordのみ拾う"
"0","sms_freq_words <- findFreqTerms(data_dtm_train, 5)"
"0",""
"0","# 5文字以上見つかったWordだけを学習・テストデータに使う"
"0","sms_dtm_freq_train <- data_dtm_train[ , sms_freq_words]"
"0","sms_dtm_freq_test <- data_dtm_test[ , sms_freq_words]"
"0",""
"0","# 文字があるかないかの2値に変換する関数"
"0","convert_counts <- function(x) {"
"0","  x <- ifelse(x > 0, ""Yes"", ""No"")"
"0","}"
"0",""
"0","# 数値データをYes/Noのデータに変換"
"0","sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)"
"0","sms_test <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)"
